{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第 9 章: 基本的なデータ分析パイプラインの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューヨーク市のタクシー運行データ（[NYC Taxi Dataset](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)）を使用して、データ分析の一般的なワークフローを実装します。</br>\n",
    "NYC Taxi Datasetは、実際のタクシー運行記録に関するオープンなデータセットで、データエンジニアリングの学習に広く使用されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生データの取り込みからIcebergテーブルへの保存、Apache Sparkでの変換・集計、そしてApache Supersetでのダッシュボード作成まで、実際のデータ分析で必要となる一連の処理を体験します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のステップでパイプラインを構築します。\n",
    "\n",
    "1. **データ取り込み**：NYC TaxiデータをParquet形式で取得し、初期データを確認する\n",
    "2. **Icebergテーブルへの保存**：取得したデータをIcebergテーブルとして保存する\n",
    "3. **データ変換と集計**：Sparkを使用してデータの変換と集計処理を実行し、分析用の集計テーブルを作成する\n",
    "4. **可視化**：オープンソースの可視化ツールであるApache Superset[^superset]からTrinoを経由してIcebergテーブルにアクセスし、インタラクティブなダッシュボードを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境のセットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, sum, count, hour, dayofweek, month, year, date_format, to_date\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "CATALOG = \"demo\"\n",
    "CATALOG_URL = \"http://server:8181/\"\n",
    "S3_ENDPOINT = \"http://minio:9000\"\n",
    "SPARK_VERSION = pyspark.__version__\n",
    "SPARK_MINOR_VERSION = '.'.join(SPARK_VERSION.split('.')[:2])\n",
    "ICEBERG_VERSION = \"1.8.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparkSessionの作成\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"NYC Taxi Data Pipeline\")\n",
    "        .config(\"spark.jars.packages\", f\"org.apache.iceberg:iceberg-spark-runtime-{SPARK_MINOR_VERSION}_2.12:{ICEBERG_VERSION},org.apache.iceberg:iceberg-aws-bundle:{ICEBERG_VERSION}\")\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}.type\", \"rest\")\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}.uri\", CATALOG_URL)\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}.s3.endpoint\", S3_ENDPOINT)\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}.view-endpoints-supported\", \"true\")\n",
    "        .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "        .config(\"spark.sql.defaultCatalog\", CATALOG)\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カタログとデータベースの作成\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS nyc_taxi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NYC Taxiデータの取得と初期探索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ハンズオン環境には、2022年1月分のタクシー運行記録がParquet形式で保存されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC Taxiデータの読み込み（既にDockerイメージ内に配置済み）\n",
    "df_taxi = spark.read.parquet(\"/home/jovyan/data/yellow_tripdata_2022-01.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの概要を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"レコード数: {df_taxi.count():,}\")\n",
    "print(f\"カラム数: {len(df_taxi.columns)}\")\n",
    "df_taxi.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi.select(\"trip_distance\", \"fare_amount\", \"tip_amount\", \"total_amount\") \\\n",
    "    .summary(\"count\", \"mean\", \"stddev\", \"min\", \"max\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Icebergテーブルへのデータ保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得したデータを保存するIcebergテーブルを作成します。</br>\n",
    "ここで、ユーザーからのヒアリングを通じて、タクシー運行データを分析する際に乗車日時（`tpep_pickup_datetime`）を`WHERE`句で指定することが分かったとしましょう。そこで、パフォーマンス向上のため、乗車日時（`tpep_pickup_datetime`）をもとに日付単位のパーティショニングすることにします"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tpep_pickup_datetime`カラムは`timestamp`型なので、そのままパーティショニングに使用した場合、細かい粒度でパーティションが作成されてしまいます。そこで、テーブル作成時にTransform（変換）機能を使用することで、`tpep_pickup_datetime`カラムを日付単位でパーティショニングするように設定（`PARTITIONED BY (day(tpep_pickup_datetime))`）しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TABLE demo.nyc_taxi.yellow_trips_raw (\n",
    "    VendorID BIGINT,\n",
    "    tpep_pickup_datetime TIMESTAMP_NTZ,\n",
    "    tpep_dropoff_datetime TIMESTAMP_NTZ,\n",
    "    passenger_count DOUBLE,\n",
    "    trip_distance DOUBLE,\n",
    "    RatecodeID DOUBLE,\n",
    "    store_and_fwd_flag STRING,\n",
    "    PULocationID BIGINT,\n",
    "    DOLocationID BIGINT,\n",
    "    payment_type BIGINT,\n",
    "    fare_amount DOUBLE,\n",
    "    extra DOUBLE,\n",
    "    mta_tax DOUBLE,\n",
    "    tip_amount DOUBLE,\n",
    "    tolls_amount DOUBLE,\n",
    "    improvement_surcharge DOUBLE,\n",
    "    total_amount DOUBLE,\n",
    "    congestion_surcharge DOUBLE,\n",
    "    airport_fee DOUBLE\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (day(tpep_pickup_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DESCRIBE TABLE demo.nyc_taxi.yellow_trips_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi.writeTo(\"demo.nyc_taxi.yellow_trips_raw\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM demo.nyc_taxi.yellow_trips_raw limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. データ変換と集計テーブルの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、タクシー会社の運営におけるドライバーの配置を効率化するための分析を行います。たとえば、朝の通勤ラッシュ時にマンハッタンのビジネス街に十分な台数を配置できなければ、多くの乗客を逃してしまいます。</br>\n",
    "一方で、需要の少ない深夜に過剰な台数を配置すれば、ドライバーの待機時間が増えて効率が悪化します。このような課題を解決するために、生の運行データから「いつ」「どこで」需要が高まるかを分析できる集計テーブルを作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 時間別集計テーブル（hourly_stats）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "時間帯ごとの需要パターンを把握するための集計テーブルを作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このテーブルから、「朝8時台にどのエリアで最も需要が高いか」といった情報を簡単に取得できます。たとえば、朝の通勤時間帯にマンハッタンのビジネス街で需要が集中していることが分かれば、その時間帯にドライバーを集中して配置できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "    \n",
    "CREATE OR REPLACE TABLE demo.nyc_taxi.hourly_stats\n",
    "USING iceberg\n",
    "AS\n",
    "SELECT\n",
    "    date(tpep_pickup_datetime) as pickup_date,\n",
    "    hour(tpep_pickup_datetime) as pickup_hour,\n",
    "    PULocationID as pickup_location_id,\n",
    "    COUNT(*) as trip_count,\n",
    "    AVG(trip_distance) as avg_distance,\n",
    "    AVG(fare_amount) as avg_fare,\n",
    "    AVG(tip_amount) as avg_tip,\n",
    "    SUM(total_amount) as total_revenue\n",
    "FROM demo.nyc_taxi.yellow_trips_raw\n",
    "WHERE tpep_pickup_datetime IS NOT NULL\n",
    "    AND trip_distance > 0\n",
    "    AND fare_amount > 0\n",
    "GROUP BY date(tpep_pickup_datetime), hour(tpep_pickup_datetime), PULocationID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 日別集計テーブル（daily_stats）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "曜日による需要の違いを分析するための集計テーブルを作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このテーブルから、「平日と週末で需要がどう変わるか」を把握できます。たとえば、週末は観光地への移動が増え、平日はビジネス街への短距離移動が中心になるといったパターンが見えてきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TABLE demo.nyc_taxi.daily_stats\n",
    "USING iceberg\n",
    "AS\n",
    "SELECT\n",
    "    date(tpep_pickup_datetime) as pickup_date,\n",
    "    dayofweek(date(tpep_pickup_datetime)) as day_of_week,\n",
    "    CASE\n",
    "        WHEN dayofweek(date(tpep_pickup_datetime)) IN (1, 7) THEN 'Weekend'\n",
    "        ELSE 'Weekday'\n",
    "    END as day_type,\n",
    "    COUNT(*) as trip_count,\n",
    "    AVG(trip_distance) as avg_distance,\n",
    "    AVG(fare_amount) as avg_fare,\n",
    "    AVG(CASE WHEN trip_distance > 0 THEN fare_amount / trip_distance END) as avg_fare_per_mile,\n",
    "    SUM(total_amount) as total_revenue\n",
    "FROM demo.nyc_taxi.yellow_trips_raw\n",
    "WHERE tpep_pickup_datetime IS NOT NULL\n",
    "    AND trip_distance > 0\n",
    "    AND fare_amount > 0\n",
    "GROUP BY date(tpep_pickup_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 分析クエリの実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらの集計テーブルを使って、配車担当者は時間帯別や曜日別の総乗車数を確認できます。まずはピーク時間帯を特定してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    pickup_hour,\n",
    "    SUM(trip_count) as total_trips,\n",
    "    AVG(avg_fare) as average_fare\n",
    "FROM demo.nyc_taxi.hourly_stats\n",
    "GROUP BY pickup_hour\n",
    "ORDER BY total_trips DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "曜日別の乗車パターンを分析して、平日と週末の需要の違いを把握してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- 平日と週末の比較\n",
    "SELECT \n",
    "    day_type,\n",
    "    SUM(trip_count) as total_trips,\n",
    "    AVG(avg_distance) as avg_trip_distance,\n",
    "    AVG(avg_fare) as avg_fare\n",
    "FROM nyc_taxi.daily_stats\n",
    "GROUP BY day_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Apache Supersetでの可視化\n",
    "\n",
    "作成したIcebergテーブルは、Apache Supersetから可視化できます。\n",
    "\n",
    "### Supersetへのアクセス\n",
    "- URL: http://localhost:8088\n",
    "- ユーザー名: admin\n",
    "- パスワード: admin\n",
    "\n",
    "### Trinoデータソースの設定手順\n",
    "1. 画面右上の「Settings」 → 「Database Connections」をクリック\n",
    "2. 画面右上の「Database」をクリック\n",
    "3. 「Supported databases」のプルダウンから「Trino」を選択\n",
    "4. 「SQLAlchemy URI」に以下の接続情報を入力：\n",
    "   - `trino://trino@trino:8085/iceberg`\n",
    "5. 「Test Connection」で接続を確認後、「Connect」をクリック\n",
    "\n",
    "接続が完了したら、作成した集計テーブル（`nyc_taxi.hourly_stats`、`nyc_taxi.daily_stats`）をデータセットとして登録します。これにより、ドラッグ＆ドロップで様々なチャートを作成できるようになります。  \n",
    "  \n",
    "1. 画面右上の「+」メニュー → 「Data」→「Create Dataset」をクリック\n",
    "2. Database に「Trino」を選択\n",
    "3. Schema に「nyc_taxi」を選択\n",
    "   - ここで、`nyc_taxi` は Iceberg テーブルを保存したスキーマ名です\n",
    "4. Table に「yellow_trips_raw」を選択\n",
    "5. 「CREATE DATASET AND CREATE CHART」をクリック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
