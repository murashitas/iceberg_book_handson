{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第 4 章: Apache Spark - 3\n",
    "\n",
    "本ノートブックでは、「基本的なIceberg機能の利用」および「高度なIceberg機能の利用」節で紹介されている例を実行できます。Spark Structured Streaming を Iceberg で利用する方法については、本ノートブック後半の「Spark Structured Streaming での Iceberg 利用」パートを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "CATALOG = \"my_catalog\"\n",
    "CATALOG_URL = \"http://server:8181/\"\n",
    "S3_ENDPOINT = \"http://minio:9000\"\n",
    "SPARK_VERSION = pyspark.__version__\n",
    "SPARK_MINOR_VERSION = '.'.join(SPARK_VERSION.split('.')[:2])\n",
    "ICEBERG_VERSION = \"1.8.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkSession オブジェクトを初期化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .config(\"spark.jars.packages\", f\"org.apache.iceberg:iceberg-spark-runtime-{SPARK_MINOR_VERSION}_2.12:{ICEBERG_VERSION},org.apache.iceberg:iceberg-aws-bundle:{ICEBERG_VERSION}\")\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}.type\", \"rest\")\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}.uri\", CATALOG_URL)\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}.s3.endpoint\", S3_ENDPOINT)\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}.view-endpoints-supported\", \"true\")\n",
    "        .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "        .config(\"spark.sql.defaultCatalog\", \"my_catalog\")\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) データベースの作成\n",
    "データベースを作成していない場合、以下のセルを実行してください。既にデータベースが存在する場合は、本ステップにつきましてはスキップしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE DATABASE IF NOT EXISTS db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本的なIceberg機能の利用\n",
    "### テーブルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TABLE db.sales_iceberg (\n",
    "    product_name string,\n",
    "    price decimal(10, 2),\n",
    "    customer_id bigint,\n",
    "    order_id string,\n",
    "    datetime timestamp,\n",
    "    category string) \n",
    "USING iceberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テーブルロケーションの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE TABLE db.sales_iceberg (\n",
    "    product_name string,\n",
    "    price decimal(10, 2),\n",
    "    customer_id bigint,\n",
    "    order_id string,\n",
    "    datetime timestamp,\n",
    "    category string) \n",
    "USING iceberg\n",
    "LOCATION 's3://amzn-s3-demo-bucket/custom-path'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テーブルプロパティの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE TABLE db.sales_iceberg (\n",
    "    product_name string,\n",
    "    price decimal(10, 2),\n",
    "    customer_id bigint,\n",
    "    order_id string,\n",
    "    datetime timestamp,\n",
    "    category string)\n",
    "USING iceberg\n",
    "TBLPROPERTIES (\n",
    "    'write.metadata.compression-codec'='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テーブルパーティションの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE TABLE db.sales_iceberg (\n",
    "    product_name string,\n",
    "    price decimal(10, 2),\n",
    "    customer_id bigint,\n",
    "    order_id string,\n",
    "    datetime timestamp,\n",
    "    category string)\n",
    "USING iceberg\n",
    "PARTITIONED BY (category, year(datetime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テーブルデータの読み込み\n",
    "テーブルレコードの準備: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO db.sales_iceberg VALUES\n",
    "    ('tomato juice', 2.00, 1698, 'DRE8DLTFNX0MLCE8DLTFNX0MLC', TIMESTAMP '2023-07-18T02:20:58Z', 'drink'),\n",
    "    ('cocoa', 2.00, 1652, 'DR1UNFHET81UNFHET8', TIMESTAMP '2024-08-26T11:36:48Z', 'drink'),\n",
    "    ('espresso', 2.00, 1037, 'DRBFZUJWPZ9SRABFZUJWPZ9SRA', TIMESTAMP '2024-04-19T12:17:22Z', 'drink'),\n",
    "    ('broccoli', 1.00, 3092, 'GRK0L8ZQK0L8ZQ', TIMESTAMP '2023-03-22T18:48:04Z', 'grocery'),\n",
    "    ('nutmeg', 1.00, 3512, 'GR15U0LKA15U0LKA', TIMESTAMP '2024-02-27T15:13:31Z', 'grocery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テーブルデータを読む:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM db.sales_iceberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの書き込み\n",
    "`INSERT INTO` によるデータの追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO db.sales_iceberg VALUES\n",
    "    ('tomato juice', 2.00, 1698, 'DRE8DLTFNX0MLCE8DLTFNX0MLC', TIMESTAMP '2023-07-18T02:20:58Z', 'drink'),\n",
    "    ('cocoa', 2.00, 1652, 'DR1UNFHET81UNFHET8', TIMESTAMP '2024-08-26T11:36:48Z', 'drink'),\n",
    "    ('espresso', 2.00, 1037, 'DRBFZUJWPZ9SRABFZUJWPZ9SRA', TIMESTAMP '2024-04-19T12:17:22Z', 'drink'),\n",
    "    ('broccoli', 1.00, 3092, 'GRK0L8ZQK0L8ZQ', TIMESTAMP '2023-03-22T18:48:04Z', 'grocery'),\n",
    "    ('nutmeg', 1.00, 3512, 'GR15U0LKA15U0LKA', TIMESTAMP '2024-02-27T15:13:31Z', 'grocery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`UPDATE` によるデータの更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE db.sales_iceberg \n",
    "SET product_name = 'white mocha',price = 4.0, datetime = CURRENT_TIMESTAMP\n",
    "WHERE product_name = 'espresso'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DELETE` によるデータの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DELETE FROM db.sales_iceberg WHERE year(datetime) < 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高度なIceberg機能の利用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTAS によるテーブルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE TABLE db.sales_iceberg_ctas\n",
    "USING iceberg\n",
    "AS SELECT * FROM db.sales_iceberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テーブル作成後、テーブルデータについて確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM db.sales_iceberg_ctas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スキーマ進化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スキーマ進化実行前に `sales_iceberg` テーブルのカラムを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DESCRIBE db.sales_iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE db.sales_iceberg ADD COLUMN description string AFTER product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE db.sales_iceberg ADD COLUMN description string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パーティション進化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE db.sales_iceberg ADD PARTITION FIELD category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ビュー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE VIEW db.sales_iceberg_analysis_view AS \n",
    "SELECT category, sum(price) as total_sales, count(*) as count_by_year, year(datetime) as year\n",
    "FROM db.sales_iceberg \n",
    "GROUP BY category, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM db.sales_iceberg_analysis_view ORDER BY year DESC, category ASC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タイムトラベルクエリ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テーブルに新たなデータを追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO db.sales_iceberg VALUES\n",
    "    ('broccoli', 1.00, 3092, 'GRK0L8ZQK0L8ZQ', TIMESTAMP '2023-03-22T18:48:04Z', 'grocery'),\n",
    "    ('nutmeg', 1.00, 3512, 'GR15U0LKA15U0LKA', TIMESTAMP '2024-02-27T15:13:31Z', 'grocery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在のテーブルデータを確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM db.sales_iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM db.sales_iceberg TIMESTAMP AS OF '<INSERT する前の時間を入力 (例: 2025-03-28 10:00:00)>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### メタデータテーブルクエリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM db.sales_iceberg.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM db.sales_iceberg.snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGE INTO によるデータの更新と追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "MERGE INTO db.sales_iceberg_w t\n",
    "USING db.sales_logs s\n",
    "ON t.order_id = s.order_id\n",
    "WHEN MATCHED THEN \n",
    "    UPDATE SET \n",
    "        t.product_name=s.product_name, \n",
    "        t.price=s.price, \n",
    "        t.datetime=s.datetime\n",
    "WHEN NOT MATCHED THEN INSERT *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM db.sales_iceberg_w ORDER BY category, product_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WHEN NOT MATCHED BY SOURCE\n",
    "sales_logs へ新たに 2 レコードを追加します。`mocha` は古いレコーとがたまたま流れてきてしまったことを想定しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO db.sales_logs VALUES\n",
    "    ('mocha', 4.00, 1652, 'DR1UNFHET81UNFHET8', TIMESTAMP '2013-11-26T12:49:43Z', 'drink'),\n",
    "    ('egg', 1.00, 3176, 'GRVQARCD6COVQARCD6CO', TIMESTAMP '2025-02-10 11:15:31', 'grocery');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM db.sales_logs ORDER BY category, product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "MERGE INTO db.sales_iceberg_w t\n",
    "USING db.sales_logs s\n",
    "ON t.order_id = s.order_id\n",
    "WHEN MATCHED AND t.datetime < s.datetime THEN \n",
    "    UPDATE SET \n",
    "        t.product_name=s.product_name, \n",
    "        t.price=s.price, \n",
    "        t.datetime=s.datetime\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "WHEN NOT MATCHED BY SOURCE THEN DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM db.sales_iceberg_w ORDER BY category, product_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Spark Structured Streaming での Iceberg 利用\n",
    "### (Optional) 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず SparkSession を初期化します。既に初期化してしまっている場合は、本カーネルを restart してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "CATALOG = \"my_catalog\"\n",
    "CATALOG_URL = \"http://server:8181/\"\n",
    "S3_ENDPOINT = \"http://minio:9000\"\n",
    "SPARK_VERSION = pyspark.__version__\n",
    "SPARK_MINOR_VERSION = '.'.join(SPARK_VERSION.split('.')[:2])\n",
    "ICEBERG_VERSION = \"1.8.1\"\n",
    "MINIO_ACCESS_KEY = \"admin\"\n",
    "MINIO_SECRET_KEY = \"password\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .config(\"spark.jars.packages\", f\"org.apache.iceberg:iceberg-spark-runtime-{SPARK_MINOR_VERSION}_2.12:{ICEBERG_VERSION},org.apache.iceberg:iceberg-aws-bundle:{ICEBERG_VERSION},org.apache.hadoop:hadoop-aws:3.2.4,org.apache.hadoop:hadoop-client:3.2.4\")\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}.type\", \"rest\")\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}.uri\", CATALOG_URL)\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}.s3.endpoint\", S3_ENDPOINT)\n",
    "        .config(f\"spark.sql.catalog.{CATALOG}.view-endpoints-supported\", \"true\")\n",
    "        .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "        .config(\"spark.sql.defaultCatalog\", \"my_catalog\")\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", MINIO_ACCESS_KEY)\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", MINIO_SECRET_KEY)\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", S3_ENDPOINT)\n",
    "        .config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事前に `sales_iceberg` と `sales_iceberg_analysis` Iceberg テーブルが必要なため、テーブルが存在しない場合は作成しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TABLE db.sales_iceberg (\n",
    "    product_name string,\n",
    "    price decimal(10, 2),\n",
    "    customer_id bigint,\n",
    "    order_id string,\n",
    "    datetime timestamp,\n",
    "    category string) \n",
    "USING iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TABLE db.sales_iceberg_analysis AS \n",
    "SELECT category, sum(price) as total_sales, count(*) as count_by_year, year(datetime) as year\n",
    "FROM db.sales_iceberg \n",
    "GROUP BY category, year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事前に、本リポジトリの `sameple-data` ディレクトリ配下に存在する `data.json` を `s3://amzn-s3-demo-bucket/spark/streaming/input` 配下にアップロードします。アップロード手順については、[MinIO にファイルをアップロードする](https://github.com/murashitas/iceberg_book_handson#minio-にファイルをアップロードする)を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Streaming 経由での Iceberg テーブルへの書き込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.readStream.format(\"json\")\n",
    "        .schema(\"product_name STRING, price DECIMAL(10, 2), customer_id BIGINT, order_id STRING, datetime TIMESTAMP, category STRING\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"cleanSource\", \"archive\")\n",
    "        .option(\"sourceArchiveDir\", \"s3a://amzn-s3-demo-bucket/spark/streaming/input-archives\")\n",
    "        .load(\"s3a://amzn-s3-demo-bucket/spark/streaming/input\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON ファイルのデータを読み込んで、Iceberg テーブルに書き込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = (\n",
    "    df.writeStream \n",
    "        .format(\"iceberg\")\n",
    "        .outputMode(\"append\")\n",
    "        .option(\"checkpointLocation\", \"s3a://amzn-s3-demo-bucket/spark/streaming/checkpoints\")\n",
    "        .trigger(processingTime=\"5 seconds\")\n",
    "        .toTable(\"db.sales_iceberg\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数秒待って `db.sales_iceberg` にデータが書き込まれたか確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM db.sales_iceberg LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "書き込まれたことを確認したら、一度 Structured Streaming の処理を停止します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sales_iceberg` テーブルからデータを読み出し、集計結果を `sales_iceberg_analysis` にストリーミング書き込みする\n",
    "次に Iceberg テーブルから、ストリーミング読み出しを行い、別の Iceberg テーブルにストリーミング書き込みしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.readStream.format(\"iceberg\").load(\"db.sales_iceberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, sum, count\n",
    "df_2 = (\n",
    "    df.groupBy(\"category\", year(\"datetime\").alias(\"year\"))\n",
    "        .agg(\n",
    "            sum(\"price\").alias(\"total_sales\"),\n",
    "            count(\"*\").alias(\"count_by_year\")\n",
    "        )\n",
    "        .select(\"category\", \"total_sales\", \"count_by_year\", \"year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは集計結果を `complete` モードで書き出します。これにより、`sales_iceberg_analysis` には毎回新しい集計値が書き込まれます。過去の特定の時点における集計値を参照したい場合は、タイムトラベルクエリで確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = (\n",
    "    df_2.writeStream \n",
    "        .format(\"iceberg\")\n",
    "        .outputMode(\"complete\")\n",
    "        .option(\"checkpointLocation\", \"s3a://amzn-s3-demo-bucket/spark/streaming/checkpoints-iceberg\") # 本ノートブックでは別の checkpoint を指定しています。\n",
    "        .trigger(processingTime=\"5 seconds\")\n",
    "        .toTable(\"db.sales_iceberg_analysis\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "書き込みが完了したら、`sales_iceberg_analysis` を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM db.sales_iceberg_analysis ORDER BY category, year DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "書き込まれたことを確認したら、再度 Structured Streaming の処理を停止します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 複雑な操作の実行\n",
    "`sales_iceberg` に対してストリーミング Upsert 処理を行いながら、コンパクション処理も実行します。まずは、この時点における `sales_iceberg` テーブルにおけるレコード数を確認しておきましょう。`5000` と出力されるはずです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT count(*) FROM db.sales_iceberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON ファイルをデータソースとして読み込みましょう。本リポジトリの `sameple-data` ディレクトリ配下に存在する `data-add.json` を `s3://amzn-s3-demo-bucket/spark/streaming/input` 配下にアップロードします。アップロード手順については、[MinIO にファイルをアップロードする](https://github.com/murashitas/iceberg_book_handson#minio-にファイルをアップロードする)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.readStream.format(\"json\")\n",
    "        .schema(\"product_name STRING, price DECIMAL(10, 2), customer_id BIGINT, order_id STRING, datetime TIMESTAMP, category STRING\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"cleanSource\", \"archive\")\n",
    "        .option(\"sourceArchiveDir\", \"s3a://amzn-s3-demo-bucket/spark/streaming/input-archives\")\n",
    "        .load(\"s3a://amzn-s3-demo-bucket/spark/streaming/input\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_df, batch_id):\n",
    "    batch_df.createOrReplaceGlobalTempView(\"tmp\")\n",
    "\n",
    "    spark.sql(\"\"\"\n",
    "    MERGE INTO db.sales_iceberg t\n",
    "    USING global_temp.tmp s\n",
    "    ON t.order_id = s.order_id\n",
    "    WHEN MATCHED THEN\n",
    "        UPDATE SET t.product_name = s.product_name, t.price = s.price, t.datetime = s.datetime\n",
    "    WHEN NOT MATCHED THEN INSERT *\n",
    "    \"\"\")\n",
    "\n",
    "    if batch_id % 20 == 0:\n",
    "        spark.sql(\"\"\"\n",
    "        CALL system.rewrite_data_files (\n",
    "            table => 'db.sales_iceberg', options => map('min-input-files', '5')\n",
    "        )\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = (\n",
    "    df.writeStream\n",
    "        .foreachBatch(process_batch)\n",
    "        .option(\"checkpointLocation\", \"s3a://amzn-s3-demo-bucket/spark/streaming/checkpoints-iceberg-merge\") # 本ノートブックでは別の checkpoint を指定しています。\n",
    "        .trigger(processingTime=\"10 seconds\")\n",
    "        .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のクエリを実行し、新たなレコードが書き込まれたことを確認したら、再度 Structured Streaming の処理を停止します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT count(*) FROM db.sales_iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
